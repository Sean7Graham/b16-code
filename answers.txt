Q1

Q1.1 - Radix Sort

Sort integers based on their most significant binary digit at each iteration, starting 
with the most significant digit. Can then be called recursively on the subsequences
to sort with respect to the next most significant binary digit.

For each digit, the algorithm must perform a sorting of each digit, of complexity
O(n). This must be done for all k binary digits, so the overall complexity is O(kn).


Q2

Q2.1 - ArrayInsert

Time complexity: At the worst case, the time complexity is O(n), when the element to
insert is at the beginning of the array. In this case, n copy operations must occur
(replacing A_n with A_n-1, A_n-1 with A_n-2 etc.)

Q2.2 - part_1/array_delete_hpp


(TODO Q4)

TODO Q5


Q6.3



Q7 

Q7.1


PriorityEnqueue(Q,x):
    i <- Q.size
    Q.A_i <- x
    interpret (Q.A_0,..,Q.A_i) as a complete binary tree T, and let S be the subtree
    rooted at A_i
    SiftUp(S)
    Q.size <- i+1

BuildHeapAlt(A):
    For i = 1,..,|A|-1 do
        Intepret(A_0,..,A_i) as a binary search tree T with binary search tree S
        rooted at A_i
        SiftUp(S)

PriorityEnqueue inserts a single element into an existing heap, whereas BuildHeapAlt
constructs a new heap from an existing array. If PriorityEnqueue is called to add each
element in the array to the heap one at a time, the ouput of both algorithms will be 
the same.


BuildHeap(A):
    For i = floor(|A|/2)-1,..,0 do
        Interpret (A_i,..,A_|A|-1) as a complete binary tree S 
        SiftDown(S)

BuildHeap has complexity O(n) as proven in the notes

BuildHeapAlt:

Calling SiftUp has computational complexity proportional to the height of the node it is 
called on.

SiftUp(0) = 0
SiftUp(1) = 1 etc.

There are 2^h nodes at depth h (total nodes of the tree 2^h+1 - 1), so the overall cost can 
be obtained by mutliplying the cost of calling SiftUp at a depth of h, by the number of nodes
at depth h, for every layer of the tree:

h*(2^h) + (h-1)*2^(h-1) ... + 1*2^1 + 1.

This summation evaluates to a complexity of theta(h * 2^h) == theta(nlog(n)), recalling that 
2^h = n.

BuildHeap, with complexity theta(n), is therefore faster than BuildHeapAlt

Q7.2

Consider an array A sorted in descending value. This is the array representation of a max 
heap. However, tsorting an unsorted array A has computational cost of at least 
O(nlog(n)), and so it more computatioanlly taxing than calling BuildHeap.

Q7.3

If the priority of an element in the heap is updated, the heap property of the binary tree can be
restored by calling SiftUp on that node, with associated computational cost O(log(n)), althought this 
requires knowledge of the location in the array of this value.


Q8

Q8.1

Consider partitioning the set of all keys k, a finite set K (the universe) into m
distinct subsets K_i such that h(k) = i for k in K_i. We have
        
                            sum_{m-1}{i=0} K_i = K

Starting with the result given in the question,

                            m * n <= |K|
                                  <= |sum_{m-1}{i=0} K_i|
                                  <= sum_{m-1}{i=0} |K_i|
                                  <= m * |max_{i=0,..,m-1} K_i|
                                  <= m * max_{i=0,..,m-1} |K_i|
                            
                                n <= max_{i=0,..,m-1} |K_i|

And therefore the maximum subset of K as defined above contains at least n distinct keys.

If all n keys hash to the same chain then, in the worst case, retrieving a key requires traversing
the entire chain, invoking a cost of O(n).

Q8.2

A hash function can take input data of arbitrary size and produce a fixed-size string of 
bytes - a hash value. The data can be represented as a number k, and a standard hash function 
h(k) can then convert k into a number in the range 0,..,m-1 with m the size of the associated
hash space.

A design goal of such a hash function is to make the chances of a random collision between two keys
extremely small. The larger the hash space, the lower the probability of two different files 
having the same hasg value. It is important that a change to the file has a significant effect on 
the hash value, so one can be highly confient that the file has not been modified if the hash values match.

Q8.3

h(c) = (sum_{q-1}{i=0} c_{q-1-i} 256^i) mod m
     = (c_{q-1} + sum_{q-1}{i=1} c_{q-1-i} * 256^i) mod m
     = [c_{q-1} + 256 * sum_{q-2}{i=0} c_{q-2-i} * 256^i] mod m
     = [c_{q-1} + 256 * [sum_{q-2}{i=0} c_{q-2-i} * 256^i mod m]] mod m 
     = [c_{q-1} + 256 * [c_{q-2} + 256 * [sum_{q-3}{i=0} c_{q-3-i} * 256^i mod m]]] mod m etc.
     => [c_{q-1} + 256 * h(c_0 -> c_{q-1})] mod m


